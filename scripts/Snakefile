import glob

## Using absolute path. 
## will leave it for now. Will include in the install script.  
BASE_DIR = workflow.basedir
BIN = BASE_DIR + "/../bin/"
SCP = BASE_DIR + "/../scripts/"
LIB = BASE_DIR + "/../lib/"
#include: BASE_DIR + "/../system.Snakefile"


GENOME = config["GENOME"]
# samples
R1 = config["R1_SUFFIX"]
R2 = config["R2_SUFFIX"]
SAMPLES = config["SAMPLES"].split()
# if the first field is *, then process every sample in the fastq folder. 
if SAMPLES[0] == "ALL":
  fastqs_p1 = glob.glob("fastq/*"+R1+"*")
  SAMPLES = [re.sub("fastq/(.+)"+ R1 +".*$","\\1",a) for a in fastqs_p1]
#print(SAMPLES)

# fastqs
FASTQ_R1 = {} 
FASTQ_R2 = {}
for sample in SAMPLES:
  fastq_r1 = glob.glob("fastq/"+sample+R1+"*")
  FASTQ_R1[sample] = fastq_r1
  fastq_r2 = glob.glob("fastq/"+sample+R2+"*")
  FASTQ_R2[sample] = fastq_r2


N_CPUS = config["N_CPUS"]
MAPQ = config["MAPQ"] or 30
#print("MAPQ:",MAPQ)
BWA_INDEX_PATH = config["BWA_INDEX_PATH"]
#print(N_CPUS)
RES_ENZYME = config["RES_ENZYME"]
## resolution for directionality index and insulation
BIN_SIZE = config["BIN_SIZE"]
BIN_NUM_DI = config["BIN_NUM_DI"]
BIN_NUM_INS = config["BIN_NUM_INS"]

PC_RES = config["PC_RES"]
## reference and annotation path
REF = BWA_INDEX_PATH + "/" + GENOME
#ANNOTATION = BIN + "/../annotation/"
SITE_POS = BIN + "/../annotation/juicebox/site_pos/"+ GENOME + "_" + RES_ENZYME + ".txt"
GENOME_FEATURE = BIN + "/../annotation/genome_features/"+ GENOME + \
    "." + RES_ENZYME + "." + str(BIN_SIZE) + ".gnf"

TSS_DICT = {
  "hg19":BIN + "../annotation/TSSs/hg19.gencode.v19.annotation.transcripts.tss10k.bed",
  "mm10":BIN + "../annotation/TSSs/mm10.gencode.vM10.annotation.transcripts.tss1k.bed"
  }
TSS = TSS_DICT[GENOME]

## read the chromosome information.
CHR = []
with open(REF+".fa.fai") as inf:
    for line in inf:
        CHR.append(line.strip().split('\t')[0])
if "chrM" in CHR: 
  CHR.remove("chrM")
#CHR = [str(x+1) for x in range(19)] + ["X"]
#print(CHR)

localrules: qc_combine combine_PC1 di_ins_bedgraph

## complete version will output the bam file in addition to the sorted txt files. 
rule all:
    input:
#        expand("{sample}/{sample}.valid_pairs.dedup.sorted.txt",sample=SAMPLES),
        expand("juicer/{sample}.hic",sample=SAMPLES),
#        expand("DI/{sample}.norm.DI.bedgraph",sample=SAMPLES),
        expand("DI/{sample}.norm.DI.TAD.bed",sample=SAMPLES),
        expand("insulation/{sample}.insulation.bedgraph",sample=SAMPLES),
#        expand("PC1/{sample}.PC1.bedgraph",sample=SAMPLES)
        
rule vanilla:
    input: 
        expand("juicer/{sample}.hic",sample=SAMPLES),
#        expand("{sample}/{sample}.norm.DI.bedgraph",sample=SAMPLES),
        expand("matrix/{sample}.{chr}.norm.DI",sample=SAMPLES,chr=CHR),
        expand("matrix/{sample}.{chr}.insulation.bed",sample=SAMPLES,chr=CHR),
        expand("DI/{sample}.norm.DI.TAD.bed",sample=SAMPLES),
        expand("DI/{sample}.norm.DI.bedgraph",sample=SAMPLES),
        expand("insulation/{sample}.insulation.bedgraph",sample=SAMPLES),
        expand("PC1/{sample}.PC1.bedgraph",sample=SAMPLES),

rule valid_pairs:
    input:
        expand("valid_pairs/{sample}.valid_pairs.dedup.sorted.txt.gz",sample=SAMPLES),
        "mapping_summary.txt"

rule scHiC:
    input:
      expand("valid_pairs.scHiC/{sample}.1k_bin.uniq.contacts.txt.gz",sample=SAMPLES),
      expand("valid_pairs.scHiC/{sample}.fragment.gz",sample=SAMPLES),
      expand("valid_pairs.scHiC/{sample}.valid_pairs.rm_hotspot.sorted.txt.gz",sample=SAMPLES),
      "mapping_summary.scHiC.txt"

rule bwa_map: 
    output: 
        # do not produce bam file.
#        "{sample}/{sample}.raw.sam",
        "valid_pairs/{sample}.valid_pairs.txt.gz",
        "valid_pairs/log/{sample}.bwa.R1.log",
    input: 
        R1 = lambda wildcards: FASTQ_R1[wildcards.sample],
        R2 = lambda wildcards: FASTQ_R2[wildcards.sample]
    params:
      pbsName=lambda wildcards: wildcards.sample
    benchmark:
        "benchmarks/{sample}.bwa_map.txt"
    threads: N_CPUS
    shell: 
        "cd valid_pairs && "
        "{SCP}/bwa_map2.sh -1 ../{input.R1}  -2 ../{input.R2} -g {REF} -p {threads} -e {SITE_POS} -n {wildcards.sample} && "
        "gzip {wildcards.sample}.valid_pairs.txt"

rule rm_low_quality_alignments:
  output:
    expand("valid_pairs/{{sample}}.valid_pairs.mapq{mapq}.txt.gz",mapq=MAPQ)
  input:
    "valid_pairs/{sample}.valid_pairs.txt.gz"
  params:
    pbsName=lambda wildcards: wildcards.sample
  shell:
    "zcat {input}|awk ' $10 >= {MAPQ} && $11 >= {MAPQ} {{print $0}}' |gzip > {output}"

rule valid_pairs_dedup:
    output: 
        "valid_pairs/{sample}.valid_pairs.dedup.sorted.txt.gz"
    input: 
        expand("valid_pairs/{{sample}}.valid_pairs.mapq{mapq}.txt.gz",mapq=MAPQ)
    params:
        pbsName=lambda wildcards: wildcards.sample
    benchmark:
        "benchmarks/{sample}.valid_pairs_dedup.txt"
    shell: 
        "zcat {input} |{LIB}/sort -k3,3 -k7,7 -k4,4n -k8,8n -u |"
        "gzip > {output}"

## reduce interaction paris connecting the same 1kb bin to 1. 
rule filter_1k_bin:
  output:
    "valid_pairs.scHiC/{sample}.1k_bin.uniq.contacts.txt.gz"
  input:
    "valid_pairs/{sample}.valid_pairs.dedup.sorted.txt.gz"
  params:
    pbsName=lambda wildcards: wildcards.sample
  shell:
    "zcat {input}| awk -v OFS='\t' '{{print $1,$3,$4,int($4/1000),$7,$8,int($8/1000)}}' "
#    "|awk -v OFS='\t' '$2!=$5 || $4!=$7 {{print $0}}'"
    "|sort -k2,2 -k5,5 -k4,4n -k7,7n -u|gzip > {output}"

## remove any 1kb bin that interact with at least 10 other locations.
rule valid_pairs_remove_hotspot:
    input:
      "valid_pairs.scHiC/{sample}.1k_bin.uniq.contacts.txt.gz"
    output:
      hotspot = "valid_pairs.scHiC/{sample}.fragment.gz",
      vp = "valid_pairs.scHiC/{sample}.valid_pairs.rm_hotspot.sorted.txt.gz"
    params:
      pbsName=lambda wildcards: wildcards.sample
    threads: 1
    shell:
      "zcat {input} | awk -v FS='\t' -v OFS='\t' '{{ a[$2\":\"$4]++;a[$5\":\"$7]++ }} END {{ for (x in a) {{  print x,a[x] }} }}' |sort -k2,2nr |gzip > {output.hotspot};"
      "awk -v FS='\t' -v OFS='\t' '(NR==FNR) {{a[$1] = FNR}} (NR!=FNR) {{ if ( !($2\":\"$4 in a) && !($5\":\"$7 in a)) {{print $0 }} }} ' "
      "<(zcat {output.hotspot}| awk '$2>10 {{print $0}}END{{print \"test\",\"test\" }}' ) <(zcat {input}) |gzip > {output.vp}"


## reduce interaction pairs connecting the same fragments to 1. 
#rule valid_pairs_dedup_fragment:
#    input: 
#      "valid_pairs/{sample}.valid_pairs.dedup.sorted.txt.gz"
#    output:
#      "valid_pairs.scHiC/{sample}.valid_pairs.frag_dedup.sorted.txt.gz"
#    params:
#      pbsName=lambda wildcards: wildcards.sample
#    threads: 2
#    shell:
#      "zcat {input} | {LIB}/sort --parallel={threads} -k3,3 -k7,7 -k5,5n -k9,9n -u |"
#      "gzip > {output}"

## remove any fragment that interact with at least 10 other locations. 
#rule valid_pairs_remove_hotspot:
#    input: 
#      "valid_pairs.scHiC/{sample}.valid_pairs.frag_dedup.sorted.txt.gz"
#    output:
#      hotspot = "valid_pairs.scHiC/{sample}.fragment.gz",
#      vp = "valid_pairs.scHiC/{sample}.valid_pairs.rm_hotspot.sorted.txt.gz"
#    params:
#      pbsName=lambda wildcards: wildcards.sample
#    threads: 1 
#    shell:      
#      "zcat {input} | awk -v FS='\t' -v OFS='\t' '{{ a[$3\":\"$5]++;a[$7\":\"$9]++ }} END {{ for (x in a) {{  print x,a[x] }} }}' |sort -k2,2nr |gzip > {output.hotspot};"
#      "awk -v FS='\t' -v OFS='\t' '(NR==FNR) {{a[$1] = FNR}} (NR!=FNR) {{ if ( !($3\":\"$5 in a) && !($7\":\"$9 in a)) {{print $0 }} }}' "
#      "<(zcat {output.hotspot}| awk '$2>10 {{print $0}}' ) <(zcat {input}) |gzip > {output.vp}"

rule txt2juicer:
    output:
        "juicer/{sample}.hic"
    input:
        "valid_pairs/{sample}.valid_pairs.dedup.sorted.txt.gz"
    benchmark:
        "benchmarks/{sample}.txt2juicer.txt"
    threads: 1
    params:
        pbsName=lambda wildcards: wildcards.sample
    shell:
        "java -jar {LIB}/juicer_tools.jar pre -q {MAPQ} -f {SITE_POS} {input} {output} {GENOME}"

rule juicer2matrix:
  output: 
    ascNorm = "matrix/{sample}/{sample}.{chr}.norm.asc"
  input:
    "juicer/{sample}.hic"
  params:
    pbsName=lambda wildcards: wildcards.sample
  threads:1
  shell:
    "chr_size=$(awk -v chr=chr{wildcards.chr} '{{ if($1==chr)print $2}}' {REF}.fa.fai) && " 
    "{LIB}/straw KR {input} {wildcards.chr} {wildcards.chr} BP {BIN_SIZE} |"
    "{SCP}/col2mat.awk -v chr={wildcards.chr} -v bin_size={BIN_SIZE} "
    "-v chr_size=${{chr_size}} > {output}"


rule matrix2di: 
  input: 
    "matrix/{sample}/{sample}.{chr}.norm.asc"
  output:
    "matrix/{sample}/{sample}.{chr}.norm.DI"
  params:
    pbsName=lambda wildcards: wildcards.sample
  shell:
    "Rscript {SCP}/asc2di.R {input} {wildcards.chr} {BIN_SIZE} {BIN_NUM_DI} {output}"

rule matrix2ins:
  input: 
    "matrix/{sample}/{sample}.{chr}.norm.asc"
  output: 
    "matrix/{sample}/{sample}.{chr}.insulation.bed"
  params:
    pbsName=lambda wildcards: wildcards.sample
  shell:
    "Rscript {SCP}/mat2insulation.R  -m {input}  -b {BIN_SIZE} "
    " -w $(({BIN_SIZE}*{BIN_NUM_INS})) -c {wildcards.chr} -o {output}"

## juicer to OE matrix and to PCA analysis.
rule juicer2PC1: 
  output:
    PC1 = "PC1/{sample}/{sample}.{chr}.PC1",
    oe = temp("matrix/{sample}/{sample}.{chr}.oe"),
  input: 
    "juicer/{sample}.hic"
  benchmark:
    "benchmarks/{sample}.{chr}.juicer2oe.txt"
  threads: 1
  params:
      pbsName=lambda wildcards: wildcards.sample
  shell: 
    "java -jar {LIB}/juicer_tools.jar dump oe KR {input} {wildcards.chr} {wildcards.chr} BP {PC_RES} "
    "> {output.oe};Rscript {SCP}/calc_PC1.r {output.oe} {wildcards.chr} {PC_RES} {TSS} > {output.PC1}"
    
rule combine_PC1: 
  output: 
    "PC1/{sample}.PC1.bedgraph"
  input: 
    expand("PC1/{{sample}}/{{sample}}.{chr}.PC1",chr=CHR),
  threads: 1
  params:
    pbsName=lambda wildcards: wildcards.sample
  shell:
    "cat {input} > {output}" 

rule di2tad: 
    output: 
        "DI/{sample}.norm.DI.TAD.bed"
    input:
        expand("matrix/{{sample}}/{{sample}}.{chr}.norm.DI",chr=CHR)
    benchmark:
        "benchmarks/{sample}.di2tad.txt"
    threads: 1
    params:
        pbsName=lambda wildcards: wildcards.sample
    log:
        "DI/log/{sample}.di2tad.log"
    shell:
        "cat {input} |awk '!/NA|-Inf/' - > DI/{wildcards.sample}.norm.DI; "
        "{LIB}/DI2TAD.sh DI/{wildcards.sample}.norm.DI {REF} {BIN_SIZE} >& {log};"

rule di_ins_bedgraph:
    output: 
        di = "DI/{sample}.norm.DI.bedgraph",
        ins = "insulation/{sample}.insulation.bedgraph"
    input: 
        di = expand("matrix/{{sample}}/{{sample}}.{chr}.norm.DI",chr=CHR),
        ins = expand("matrix/{{sample}}/{{sample}}.{chr}.insulation.bed",chr=CHR)
    threads: 1
    params:
        pbsName=lambda wildcards: wildcards.sample
    shell:
        "cat {input.di} |  awk '!/NA|-Inf/' - > {output.di};"
        "cat {input.ins} |  awk '!/NA|-Inf/' - > {output.ins}"

rule qc_per_sample: 
  input:
      fastq = lambda wildcards: FASTQ_R1[wildcards.sample],
      valid_pairs = "valid_pairs/{sample}.valid_pairs.txt.gz",
      valid_nodup_pairs = "valid_pairs/{sample}.valid_pairs.dedup.sorted.txt.gz"
  output: 
      "qc/{sample}.mapping_summary.txt"
  threads: 1
  params:
      pbsName=lambda wildcards: wildcards.sample,
      # determine the fastq file compression format
      Read = lambda wildcards: "zcat" if FASTQ_R1[wildcards.sample][0][-3:] == ".gz" else "bzcat" if FASTQ_R1[wildcards.sample][0][-4:] == ".bz2" else  "cat"
  shell: 
    "fa=$({params.Read} {input.fastq} |wc -l);"
    "fa=$((fa/4));"
    "vp=$(zcat {input.valid_pairs}|wc -l|cut -f 1 -d' ' );"
    "vpNodup=$(zcat {input.valid_nodup_pairs}|wc -l|cut -f 1 -d' ' );"
    "cis_pair=$(zcat {input.valid_nodup_pairs}|awk -v FS='\t' -v OFS='\t' '{{if ($3 == $7){{ m++;if ( $8-$4 >=15000 || $8-$4 <= -15000 ) {{n++}} }} }}END {{ print m,n}}'  );"
    "echo -e \"Sample\tRaw\tVP\tVP_uniq\tVP_cis\tVP_cis15k\"  > {output};"
    "echo -e \"{wildcards.sample}\t$fa\t$vp\t$vpNodup\t$cis_pair\" >> {output}"

rule qc_per_sample_scHiC:
  input:
      fastq = lambda wildcards: FASTQ_R1[wildcards.sample],
      valid_pairs = "valid_pairs/{sample}.valid_pairs.txt.gz",
      valid_nodup_pairs = "valid_pairs/{sample}.valid_pairs.dedup.sorted.txt.gz",
      valid_nodup_frag = "valid_pairs.scHiC/{sample}.valid_pairs.rm_hotspot.sorted.txt.gz"
  output:
      "qc/{sample}.mapping_summary.scHiC.txt"
  threads: 1
  params:
      pbsName=lambda wildcards: wildcards.sample,
      # determine the fastq file compression format
      Read = lambda wildcards: "zcat" if FASTQ_R1[wildcards.sample][0][-3:] == ".gz" else "bzcat" if FASTQ_R1[wildcards.sample][0][-4:] == ".bz2" else  "cat"
  shell:
    "fa=$({params.Read} {input.fastq} |wc -l);"
    "fa=$((fa/4));"
    "vp=$(zcat {input.valid_pairs}|wc -l|cut -f 1 -d' ' );"
    "vpNodup=$(zcat {input.valid_nodup_pairs}|wc -l|cut -f 1 -d' ' );"
    "cis_pair=$(zcat {input.valid_nodup_frag}|awk '$3!=$7 || $4-$8 >5000 || $8-$4 >5000 {{cnts++}} END{{print cnts}}');" 
    "echo -e \"Sample\tRaw\tVP\tVP_uniq\tVP_cis5kORtrans\"  > {output};"
    "echo -e \"{wildcards.sample}\t$fa\t$vp\t$vpNodup\t$cis_pair\" >> {output}"


rule qc_combine: 
  input: 
      expand("qc/{sample}.mapping_summary.txt", sample=SAMPLES)
  output: 
      "mapping_summary.txt"
  threads: 1
  params:
    pbsName="All"
  shell:
    "cat {input} | awk -v OFS='\t' '{{ if (NR==1) {{ print $0 }} else {{ if (NR%2==0) {{ print $0 }} }} }}' > {output};"

rule qc_combine_scHiC:
  input:
      expand("qc/{sample}.mapping_summary.scHiC.txt", sample=SAMPLES)
  output:
      "mapping_summary.scHiC.txt"
  threads: 1
  params:
    pbsName="All"
  shell:
    "cat {input} | awk -v OFS='\t' '{{ if (NR==1) {{ print $0 }} else {{ if (NR%2==0) {{ print $0 }} }} }}' > {output};"

# rule to convert sam to bam
# sort bam
# dedup bam



